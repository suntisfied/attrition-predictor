{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Predicting Probability of Quitting and Providing Prevention Hints"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Necessary Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import roc_auc_score, classification_report, roc_curve, auc, mean_squared_error, r2_score\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
                "from xgboost import XGBClassifier, XGBRegressor\n",
                "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
                "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
                "import numpy as np\n",
                "from collections import Counter\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load the Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
                        "       'average_montly_hours', 'time_spend_company', 'Work_accident', 'left',\n",
                        "       'promotion_last_5years', 'Departments', 'salary'],\n",
                        "      dtype='object')\n"
                    ]
                }
            ],
            "source": [
                "# Load the dataset\n",
                "file_path = 'D:\\\\Python_Projects\\\\attrition_predictor\\\\data\\\\HR_Dataset.csv'\n",
                "df = pd.read_csv(file_path)\n",
                "\n",
                "# Strip trailing spaces from column names\n",
                "df.columns = df.columns.str.strip()\n",
                "\n",
                "# Check column names\n",
                "print(df.columns)\n",
                "\n",
                "# Correct column names\n",
                "department_col = 'Departments'\n",
                "salary_col = 'salary'\n",
                "\n",
                "# Encode categorical features into numerical values for correlation analysis\n",
                "df_encoded = df.copy()\n",
                "df_encoded[department_col] = df_encoded[department_col].astype('category').cat.codes\n",
                "df_encoded[salary_col] = df_encoded[salary_col].astype('category').cat.codes\n",
                "\n",
                "# Calculate the correlation matrix\n",
                "corr_matrix = df_encoded.corr(numeric_only=True)\n",
                "\n",
                "# Display the heatmap with annotations for all cells\n",
                "plt.figure(figsize=(12, 8))\n",
                "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar=True, linewidths=0.5, linecolor='white')\n",
                "plt.title('Correlation Matrix with Annotations in All Cells')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Distribution and Relationships"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution of target variable\n",
                "plt.figure(figsize=(6, 4))\n",
                "sns.countplot(x='left', data=df)\n",
                "plt.title('Distribution of Employees Leaving')\n",
                "plt.xlabel('Left Company')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize relationships between features and target\n",
                "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company']\n",
                "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
                "axs = axs.flatten()\n",
                "\n",
                "for i, feature in enumerate(features):\n",
                "    sns.boxplot(x='left', y=feature, data=df, ax=axs[i])\n",
                "    axs[i].set_title(f'{feature} vs Left')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize categorical features\n",
                "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
                "sns.countplot(x='salary', hue='left', data=df, ax=axs[0])\n",
                "sns.countplot(x='Departments', hue='left', data=df, ax=axs[1])\n",
                "axs[0].set_title('Salary vs Left')\n",
                "axs[1].set_title('Departments vs Left')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Prepare the Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the feature columns and the target column for classification\n",
                "X_class = df.drop(columns=['left'])\n",
                "y_class = df['left']\n",
                "\n",
                "# Define the feature columns and the target column for regression\n",
                "X_reg = df.drop(columns=['satisfaction_level', 'left'])\n",
                "y_reg = df['satisfaction_level']\n",
                "\n",
                "# Identify categorical and numerical columns\n",
                "categorical_cols = X_class.select_dtypes(include=['object']).columns\n",
                "numerical_cols = X_class.select_dtypes(include=['int64', 'float64']).columns\n",
                "\n",
                "# Separate ordinal and nominal columns\n",
                "ordinal_cols = ['salary']\n",
                "nominal_cols = [col for col in categorical_cols if col not in ordinal_cols]\n",
                "\n",
                "# Define the ordinal encoder for the 'salary' column\n",
                "salary_categories = ['low', 'medium', 'high']\n",
                "ordinal_encoder = OrdinalEncoder(categories=[salary_categories])\n",
                "\n",
                "# Preprocessing pipeline for classification\n",
                "preprocessor_class = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', StandardScaler(), numerical_cols),\n",
                "        ('ord', ordinal_encoder, ordinal_cols),\n",
                "        ('nom', OneHotEncoder(handle_unknown='ignore'), nominal_cols)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Preprocessing pipeline for regression\n",
                "preprocessor_reg = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', StandardScaler(), X_reg.select_dtypes(include=['int64', 'float64']).columns),\n",
                "        ('ord', ordinal_encoder, ordinal_cols),\n",
                "        ('nom', OneHotEncoder(handle_unknown='ignore'), nominal_cols)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Split data into training and test sets for classification\n",
                "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
                "\n",
                "# Split data into training and test sets for regression\n",
                "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Resampling Techniques for Classification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Applying Random OverSampler...\n",
                        "Resampled dataset shape: Counter({1: 8000, 0: 8000})\n",
                        "----------------------------------------\n",
                        "Applying SMOTE...\n",
                        "Resampled dataset shape: Counter({1: 8000, 0: 8000})\n",
                        "----------------------------------------\n",
                        "Applying Borderline SMOTE...\n",
                        "Resampled dataset shape: Counter({1: 8000, 0: 8000})\n",
                        "----------------------------------------\n",
                        "Applying ADASYN...\n",
                        "Resampled dataset shape: Counter({0: 8000, 1: 7958})\n",
                        "----------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Function to resample data using different techniques\n",
                "def resample_data(X, y, sampler):\n",
                "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
                "    print(f\"Resampled dataset shape: {Counter(y_resampled)}\")\n",
                "    return X_resampled, y_resampled\n",
                "\n",
                "# Apply resampling techniques\n",
                "samplers = {\n",
                "    'Random OverSampler': RandomOverSampler(random_state=42),\n",
                "    'SMOTE': SMOTE(random_state=42),\n",
                "    'Borderline SMOTE': BorderlineSMOTE(random_state=42),\n",
                "    'ADASYN': ADASYN(random_state=42)\n",
                "}\n",
                "\n",
                "X_class_train_transformed = preprocessor_class.fit_transform(X_class_train)\n",
                "\n",
                "resampled_datasets = {}\n",
                "for name, sampler in samplers.items():\n",
                "    print(f'Applying {name}...')\n",
                "    X_resampled, y_resampled = resample_data(X_class_train_transformed, y_class_train, sampler)\n",
                "    resampled_datasets[name] = (X_resampled, y_resampled)\n",
                "    print('-' * 40)\n",
                "\n",
                "# Also include the original dataset\n",
                "resampled_datasets['Original'] = (X_class_train_transformed, y_class_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build Classification Models and Compare Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "### Evaluating models for Random OverSampler dataset ###\n",
                        "Logistic Regression: ROC AUC Score = 0.825\n",
                        "Random Forest: ROC AUC Score = 0.991\n",
                        "XGBoost: ROC AUC Score = 0.991\n",
                        "Gradient Boosting: ROC AUC Score = 0.989\n",
                        "K-Nearest Neighbors: ROC AUC Score = 0.966\n",
                        "--------------------------------------------------\n",
                        "### Evaluating models for SMOTE dataset ###\n",
                        "Logistic Regression: ROC AUC Score = 0.825\n",
                        "Random Forest: ROC AUC Score = 0.990\n",
                        "XGBoost: ROC AUC Score = 0.992\n",
                        "Gradient Boosting: ROC AUC Score = 0.987\n",
                        "K-Nearest Neighbors: ROC AUC Score = 0.968\n",
                        "--------------------------------------------------\n",
                        "### Evaluating models for Borderline SMOTE dataset ###\n",
                        "Logistic Regression: ROC AUC Score = 0.782\n",
                        "Random Forest: ROC AUC Score = 0.991\n",
                        "XGBoost: ROC AUC Score = 0.992\n",
                        "Gradient Boosting: ROC AUC Score = 0.986\n",
                        "K-Nearest Neighbors: ROC AUC Score = 0.966\n",
                        "--------------------------------------------------\n",
                        "### Evaluating models for ADASYN dataset ###\n",
                        "Logistic Regression: ROC AUC Score = 0.796\n",
                        "Random Forest: ROC AUC Score = 0.990\n",
                        "XGBoost: ROC AUC Score = 0.991\n",
                        "Gradient Boosting: ROC AUC Score = 0.987\n",
                        "K-Nearest Neighbors: ROC AUC Score = 0.965\n",
                        "--------------------------------------------------\n",
                        "### Evaluating models for Original dataset ###\n",
                        "Logistic Regression: ROC AUC Score = 0.814\n",
                        "Random Forest: ROC AUC Score = 0.991\n",
                        "XGBoost: ROC AUC Score = 0.991\n",
                        "Gradient Boosting: ROC AUC Score = 0.988\n",
                        "K-Nearest Neighbors: ROC AUC Score = 0.969\n",
                        "--------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Function to evaluate different classification models\n",
                "def evaluate_classification_models(X_train, y_train, X_test, y_test):\n",
                "    models = {\n",
                "        'Logistic Regression': LogisticRegression(),\n",
                "        'Random Forest': RandomForestClassifier(random_state=42),\n",
                "        'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
                "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
                "        'K-Nearest Neighbors': KNeighborsClassifier()\n",
                "    }\n",
                "\n",
                "    results = {}\n",
                "    for name, model in models.items():\n",
                "        pipeline = Pipeline([\n",
                "            ('model', model)\n",
                "        ])\n",
                "        pipeline.fit(X_train, y_train)\n",
                "        y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
                "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "        results[name] = roc_auc\n",
                "        print(f'{name}: ROC AUC Score = {roc_auc:.3f}')\n",
                "    return results\n",
                "\n",
                "# Evaluate models for each resampling technique\n",
                "model_results = {}\n",
                "X_class_test_transformed = preprocessor_class.transform(X_class_test)\n",
                "\n",
                "for name, (X_resampled, y_resampled) in resampled_datasets.items():\n",
                "    print(f'### Evaluating models for {name} dataset ###')\n",
                "    model_results[name] = evaluate_classification_models(X_resampled, y_resampled, X_class_test_transformed, y_class_test)\n",
                "    print('-' * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Identify Best Classification Model and Resampling Technique"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best Classification Model: XGBoost with Borderline SMOTE (ROC AUC Score = 0.992)\n"
                    ]
                }
            ],
            "source": [
                "# Find the best classification model and resampling technique\n",
                "best_auc = 0\n",
                "best_class_model = None\n",
                "best_class_sampler = None\n",
                "best_class_model_name = None\n",
                "\n",
                "for sampler, models in model_results.items():\n",
                "    for model, auc in models.items():\n",
                "        if auc > best_auc:\n",
                "            best_auc = auc\n",
                "            best_class_sampler = sampler\n",
                "            best_class_model_name = model\n",
                "            best_class_model = models[model]\n",
                "\n",
                "print(f'Best Classification Model: {best_class_model_name} with {best_class_sampler} (ROC AUC Score = {best_auc:.3f})')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Feature Importance Analysis for Classification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Feature</th>\n",
                            "      <th>Importance</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>time_spend_company</td>\n",
                            "      <td>0.193511</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>Departments_product_mng</td>\n",
                            "      <td>0.089148</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>Departments_hr</td>\n",
                            "      <td>0.084923</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>satisfaction_level</td>\n",
                            "      <td>0.082363</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>Departments_technical</td>\n",
                            "      <td>0.071499</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>Work_accident</td>\n",
                            "      <td>0.060376</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>promotion_last_5years</td>\n",
                            "      <td>0.059872</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>salary</td>\n",
                            "      <td>0.058104</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>number_project</td>\n",
                            "      <td>0.054223</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>Departments_RandD</td>\n",
                            "      <td>0.039811</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                    Feature  Importance\n",
                            "4        time_spend_company    0.193511\n",
                            "14  Departments_product_mng    0.089148\n",
                            "11           Departments_hr    0.084923\n",
                            "0        satisfaction_level    0.082363\n",
                            "17    Departments_technical    0.071499\n",
                            "5             Work_accident    0.060376\n",
                            "6     promotion_last_5years    0.059872\n",
                            "7                    salary    0.058104\n",
                            "2            number_project    0.054223\n",
                            "9         Departments_RandD    0.039811"
                        ]
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Extract feature names from the preprocessing pipeline for classification\n",
                "feature_names_num = numerical_cols.tolist()\n",
                "feature_names_ord = ordinal_cols\n",
                "feature_names_nom = preprocessor_class.named_transformers_['nom'].get_feature_names_out(nominal_cols)\n",
                "\n",
                "all_feature_names = np.concatenate([feature_names_num, feature_names_ord, feature_names_nom])\n",
                "\n",
                "# Use Random Forest or XGBoost feature importance\n",
                "best_class_model_instance = None\n",
                "if best_class_model_name == 'Random Forest':\n",
                "    best_class_model_instance = RandomForestClassifier(random_state=42)\n",
                "elif best_class_model_name == 'XGBoost':\n",
                "    best_class_model_instance = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
                "\n",
                "pipeline_class = Pipeline([\n",
                "    ('classifier', best_class_model_instance)\n",
                "])\n",
                "\n",
                "# Ensure resampled data remains a DataFrame\n",
                "X_resampled, y_resampled = resampled_datasets[best_class_sampler]\n",
                "X_resampled_df = pd.DataFrame(X_resampled, columns=all_feature_names)\n",
                "\n",
                "# Fit the pipeline\n",
                "pipeline_class.fit(X_resampled_df, y_resampled)\n",
                "\n",
                "# Extract feature importance\n",
                "feature_importances = pipeline_class.named_steps['classifier'].feature_importances_\n",
                "\n",
                "# Create a DataFrame for visualization\n",
                "importance_df = pd.DataFrame({'Feature': all_feature_names, 'Importance': feature_importances})\n",
                "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
                "\n",
                "# Plot the feature importance\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
                "plt.title('Feature Importance Analysis (Classification)')\n",
                "plt.show()\n",
                "\n",
                "importance_df.head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Build Regression Models and Compare Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Linear Regression: MSE = 0.057, R2 = 0.064\n",
                        "Decision Tree: MSE = 0.054, R2 = 0.117\n",
                        "Random Forest: MSE = 0.032, R2 = 0.483\n",
                        "XGBoost: MSE = 0.034, R2 = 0.438\n",
                        "Gradient Boosting: MSE = 0.035, R2 = 0.423\n",
                        "K-Nearest Neighbors: MSE = 0.042, R2 = 0.316\n"
                    ]
                }
            ],
            "source": [
                "# Function to evaluate different regression models\n",
                "def evaluate_regression_models(X_train, y_train, X_test, y_test):\n",
                "    models = {\n",
                "        'Linear Regression': LinearRegression(),\n",
                "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
                "        'Random Forest': RandomForestRegressor(random_state=42),\n",
                "        'XGBoost': XGBRegressor(random_state=42),\n",
                "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
                "        'K-Nearest Neighbors': KNeighborsRegressor()\n",
                "    }\n",
                "\n",
                "    results = {}\n",
                "    for name, model in models.items():\n",
                "        pipeline = Pipeline([\n",
                "            ('model', model)\n",
                "        ])\n",
                "        pipeline.fit(X_train, y_train)\n",
                "        y_pred = pipeline.predict(X_test)\n",
                "        mse = mean_squared_error(y_test, y_pred)\n",
                "        r2 = r2_score(y_test, y_pred)\n",
                "        results[name] = {'MSE': mse, 'R2': r2}\n",
                "        print(f'{name}: MSE = {mse:.3f}, R2 = {r2:.3f}')\n",
                "    return results\n",
                "\n",
                "# Evaluate regression models\n",
                "regression_results = evaluate_regression_models(\n",
                "    preprocessor_reg.fit_transform(X_reg_train),\n",
                "    y_reg_train,\n",
                "    preprocessor_reg.transform(X_reg_test),\n",
                "    y_reg_test\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Identify Best Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best Regression Model: Random Forest (R2 Score = 0.483)\n"
                    ]
                }
            ],
            "source": [
                "# Find the best regression model\n",
                "best_r2 = -float('inf')\n",
                "best_reg_model = None\n",
                "best_reg_model_name = None\n",
                "\n",
                "for model, scores in regression_results.items():\n",
                "    if scores['R2'] > best_r2:\n",
                "        best_r2 = scores['R2']\n",
                "        best_reg_model_name = model\n",
                "        best_reg_model = model\n",
                "\n",
                "print(f'Best Regression Model: {best_reg_model_name} (R2 Score = {best_r2:.3f})')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Feature Importance Analysis for Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Feature</th>\n",
                            "      <th>Importance</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>number_project</td>\n",
                            "      <td>0.364958</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>average_montly_hours</td>\n",
                            "      <td>0.242742</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>last_evaluation</td>\n",
                            "      <td>0.170182</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>time_spend_company</td>\n",
                            "      <td>0.061357</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>salary</td>\n",
                            "      <td>0.033152</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Work_accident</td>\n",
                            "      <td>0.017908</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>Departments_sales</td>\n",
                            "      <td>0.017897</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>Departments_support</td>\n",
                            "      <td>0.014888</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>Departments_technical</td>\n",
                            "      <td>0.014834</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>Departments_IT</td>\n",
                            "      <td>0.010857</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                  Feature  Importance\n",
                            "1          number_project    0.364958\n",
                            "2    average_montly_hours    0.242742\n",
                            "0         last_evaluation    0.170182\n",
                            "3      time_spend_company    0.061357\n",
                            "6                  salary    0.033152\n",
                            "4           Work_accident    0.017908\n",
                            "14      Departments_sales    0.017897\n",
                            "15    Departments_support    0.014888\n",
                            "16  Departments_technical    0.014834\n",
                            "7          Departments_IT    0.010857"
                        ]
                    },
                    "execution_count": 50,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Extract feature names from the preprocessing pipeline for regression\n",
                "feature_names_num_reg = X_reg.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "feature_names_ord = ordinal_cols\n",
                "feature_names_nom = preprocessor_reg.named_transformers_['nom'].get_feature_names_out(nominal_cols)\n",
                "\n",
                "all_feature_names_reg = np.concatenate([feature_names_num_reg, feature_names_ord, feature_names_nom])\n",
                "\n",
                "# Use Random Forest or XGBoost feature importance\n",
                "best_reg_model_instance = None\n",
                "if best_reg_model_name == 'Random Forest':\n",
                "    best_reg_model_instance = RandomForestRegressor(random_state=42)\n",
                "elif best_reg_model_name == 'XGBoost':\n",
                "    best_reg_model_instance = XGBRegressor(random_state=42)\n",
                "\n",
                "pipeline_reg = Pipeline([\n",
                "    ('model', best_reg_model_instance)\n",
                "])\n",
                "\n",
                "# Fit the pipeline\n",
                "pipeline_reg.fit(preprocessor_reg.fit_transform(X_reg_train), y_reg_train)\n",
                "\n",
                "# Extract feature importance\n",
                "feature_importances_reg = pipeline_reg.named_steps['model'].feature_importances_\n",
                "\n",
                "# Create a DataFrame for visualization\n",
                "importance_df_reg = pd.DataFrame({'Feature': all_feature_names_reg, 'Importance': feature_importances_reg})\n",
                "importance_df_reg = importance_df_reg.sort_values(by='Importance', ascending=False)\n",
                "\n",
                "# Plot the feature importance\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(x='Importance', y='Feature', data=importance_df_reg)\n",
                "plt.title('Feature Importance Analysis (Regression)')\n",
                "plt.show()\n",
                "\n",
                "importance_df_reg.head(10)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
